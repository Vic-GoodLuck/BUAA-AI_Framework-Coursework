{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebe8e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import paddle\n",
    "import scipy\n",
    "from omegaconf import DictConfig\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "import ppsci\n",
    "from ppsci.utils import logger\n",
    "\n",
    "\n",
    "@hydra.main(version_base=None, config_path=\"./conf\", config_name=\"VP_NSFNet2.yaml\")\n",
    "def main(cfg: DictConfig):\n",
    "    if cfg.mode == \"train\":\n",
    "        train(cfg)\n",
    "    elif cfg.mode == \"eval\":\n",
    "        evaluate(cfg)\n",
    "    else:\n",
    "        raise ValueError(f\"cfg.mode should in ['train', 'eval'], but got '{cfg.mode}'\")\n",
    "\n",
    "\n",
    "def load_data(path, N_TRAIN, NB_TRAIN, N0_TRAIN):\n",
    "    data = scipy.io.loadmat(path)\n",
    "\n",
    "    U_star = data[\"U_star\"].astype(\"float32\")  # N x 2 x T\n",
    "    P_star = data[\"p_star\"].astype(\"float32\")  # N x T\n",
    "    t_star = data[\"t\"].astype(\"float32\")  # T x 1\n",
    "    X_star = data[\"X_star\"].astype(\"float32\")  # N x 2\n",
    "\n",
    "    N = X_star.shape[0]\n",
    "    T = t_star.shape[0]\n",
    "\n",
    "    # rearrange data\n",
    "    XX = np.tile(X_star[:, 0:1], (1, T))  # N x T\n",
    "    YY = np.tile(X_star[:, 1:2], (1, T))  # N x T\n",
    "    TT = np.tile(t_star, (1, N)).T  # N x T\n",
    "\n",
    "    UU = U_star[:, 0, :]  # N x T\n",
    "    VV = U_star[:, 1, :]  # N x T\n",
    "    PP = P_star  # N x T\n",
    "\n",
    "    x = XX.flatten()[:, None]  # NT x 1\n",
    "    y = YY.flatten()[:, None]  # NT x 1\n",
    "    t = TT.flatten()[:, None]  # NT x 1\n",
    "\n",
    "    u = UU.flatten()[:, None]  # NT x 1\n",
    "    v = VV.flatten()[:, None]  # NT x 1\n",
    "    p = PP.flatten()[:, None]  # NT x 1\n",
    "\n",
    "    data1 = np.concatenate([x, y, t, u, v, p], 1)\n",
    "    data2 = data1[:, :][data1[:, 2] <= 7]\n",
    "    data3 = data2[:, :][data2[:, 0] >= 1]\n",
    "    data4 = data3[:, :][data3[:, 0] <= 8]\n",
    "    data5 = data4[:, :][data4[:, 1] >= -2]\n",
    "    data_domain = data5[:, :][data5[:, 1] <= 2]\n",
    "    data_t0 = data_domain[:, :][data_domain[:, 2] == 0]\n",
    "    data_y1 = data_domain[:, :][data_domain[:, 0] == 1]\n",
    "    data_y8 = data_domain[:, :][data_domain[:, 0] == 8]\n",
    "    data_x = data_domain[:, :][data_domain[:, 1] == -2]\n",
    "    data_x2 = data_domain[:, :][data_domain[:, 1] == 2]\n",
    "    data_sup_b_train = np.concatenate([data_y1, data_y8, data_x, data_x2], 0)\n",
    "    idx = np.random.choice(data_domain.shape[0], N_TRAIN, replace=False)\n",
    "\n",
    "    x_train = data_domain[idx, 0].reshape(data_domain[idx, 0].shape[0], 1)\n",
    "    y_train = data_domain[idx, 1].reshape(data_domain[idx, 1].shape[0], 1)\n",
    "    t_train = data_domain[idx, 2].reshape(data_domain[idx, 2].shape[0], 1)\n",
    "\n",
    "    x0_train = data_t0[:, 0].reshape(data_t0[:, 0].shape[0], 1)\n",
    "    y0_train = data_t0[:, 1].reshape(data_t0[:, 1].shape[0], 1)\n",
    "    t0_train = data_t0[:, 2].reshape(data_t0[:, 2].shape[0], 1)\n",
    "    u0_train = data_t0[:, 3].reshape(data_t0[:, 3].shape[0], 1)\n",
    "    v0_train = data_t0[:, 4].reshape(data_t0[:, 4].shape[0], 1)\n",
    "\n",
    "    xb_train = data_sup_b_train[:, 0].reshape(data_sup_b_train[:, 0].shape[0], 1)\n",
    "    yb_train = data_sup_b_train[:, 1].reshape(data_sup_b_train[:, 1].shape[0], 1)\n",
    "    tb_train = data_sup_b_train[:, 2].reshape(data_sup_b_train[:, 2].shape[0], 1)\n",
    "    ub_train = data_sup_b_train[:, 3].reshape(data_sup_b_train[:, 3].shape[0], 1)\n",
    "    vb_train = data_sup_b_train[:, 4].reshape(data_sup_b_train[:, 4].shape[0], 1)\n",
    "\n",
    "    # set test set\n",
    "    snap = np.array([0])\n",
    "    x_star = X_star[:, 0:1]\n",
    "    y_star = X_star[:, 1:2]\n",
    "    t_star = TT[:, snap]\n",
    "\n",
    "    u_star = U_star[:, 0, snap]\n",
    "    v_star = U_star[:, 1, snap]\n",
    "    p_star = P_star[:, snap]\n",
    "\n",
    "    return (\n",
    "        x_train,\n",
    "        y_train,\n",
    "        t_train,\n",
    "        x0_train,\n",
    "        y0_train,\n",
    "        t0_train,\n",
    "        u0_train,\n",
    "        v0_train,\n",
    "        xb_train,\n",
    "        yb_train,\n",
    "        tb_train,\n",
    "        ub_train,\n",
    "        vb_train,\n",
    "        x_star,\n",
    "        y_star,\n",
    "        t_star,\n",
    "        u_star,\n",
    "        v_star,\n",
    "        p_star,\n",
    "    )\n",
    "\n",
    "\n",
    "def train(cfg: DictConfig):\n",
    "    OUTPUT_DIR = cfg.output_dir\n",
    "    logger.init_logger(\"ppsci\", f\"{OUTPUT_DIR}/train.log\", \"info\")\n",
    "\n",
    "    # set random seed for reproducibility\n",
    "    SEED = cfg.seed\n",
    "    ppsci.utils.misc.set_random_seed(SEED)\n",
    "    ITERS_PER_EPOCH = cfg.iters_per_epoch\n",
    "\n",
    "    # set model\n",
    "    model = ppsci.arch.MLP(**cfg.MODEL)\n",
    "\n",
    "    # set the number of residual samples\n",
    "    N_TRAIN = cfg.ntrain\n",
    "\n",
    "    # set the number of boundary samples\n",
    "    NB_TRAIN = cfg.nb_train\n",
    "\n",
    "    # set the number of initial samples\n",
    "    N0_TRAIN = cfg.n0_train\n",
    "\n",
    "    (\n",
    "        x_train,\n",
    "        y_train,\n",
    "        t_train,\n",
    "        x0_train,\n",
    "        y0_train,\n",
    "        t0_train,\n",
    "        u0_train,\n",
    "        v0_train,\n",
    "        xb_train,\n",
    "        yb_train,\n",
    "        tb_train,\n",
    "        ub_train,\n",
    "        vb_train,\n",
    "        x_star,\n",
    "        y_star,\n",
    "        t_star,\n",
    "        u_star,\n",
    "        v_star,\n",
    "        p_star,\n",
    "    ) = load_data(cfg.data_dir, N_TRAIN, NB_TRAIN, N0_TRAIN)\n",
    "    # set dataloader config\n",
    "    train_dataloader_cfg_b = {\n",
    "        \"dataset\": {\n",
    "            \"name\": \"NamedArrayDataset\",\n",
    "            \"input\": {\"x\": xb_train, \"y\": yb_train, \"t\": tb_train},\n",
    "            \"label\": {\"u\": ub_train, \"v\": vb_train},\n",
    "        },\n",
    "        \"batch_size\": NB_TRAIN,\n",
    "        \"iters_per_epoch\": ITERS_PER_EPOCH,\n",
    "        \"sampler\": {\n",
    "            \"name\": \"BatchSampler\",\n",
    "            \"drop_last\": False,\n",
    "            \"shuffle\": False,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    train_dataloader_cfg_0 = {\n",
    "        \"dataset\": {\n",
    "            \"name\": \"NamedArrayDataset\",\n",
    "            \"input\": {\"x\": x0_train, \"y\": y0_train, \"t\": t0_train},\n",
    "            \"label\": {\"u\": u0_train, \"v\": v0_train},\n",
    "        },\n",
    "        \"batch_size\": N0_TRAIN,\n",
    "        \"iters_per_epoch\": ITERS_PER_EPOCH,\n",
    "        \"sampler\": {\n",
    "            \"name\": \"BatchSampler\",\n",
    "            \"drop_last\": False,\n",
    "            \"shuffle\": False,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    valida_dataloader_cfg = {\n",
    "        \"dataset\": {\n",
    "            \"name\": \"NamedArrayDataset\",\n",
    "            \"input\": {\"x\": x_star, \"y\": y_star, \"t\": t_star},\n",
    "            \"label\": {\"u\": u_star, \"v\": v_star, \"p\": p_star},\n",
    "        },\n",
    "        \"total_size\": u_star.shape[0],\n",
    "        \"batch_size\": u_star.shape[0],\n",
    "        \"sampler\": {\n",
    "            \"name\": \"BatchSampler\",\n",
    "            \"drop_last\": False,\n",
    "            \"shuffle\": False,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    geom = ppsci.geometry.PointCloud(\n",
    "        {\"x\": x_train, \"y\": y_train, \"t\": t_train}, (\"x\", \"y\", \"t\")\n",
    "    )\n",
    "\n",
    "    # supervised constraint s.t ||u-u_b||\n",
    "    sup_constraint_b = ppsci.constraint.SupervisedConstraint(\n",
    "        train_dataloader_cfg_b,\n",
    "        ppsci.loss.MSELoss(\"mean\"),\n",
    "        name=\"Sup_b\",\n",
    "    )\n",
    "\n",
    "    # supervised constraint s.t ||u-u_0||\n",
    "    sup_constraint_0 = ppsci.constraint.SupervisedConstraint(\n",
    "        train_dataloader_cfg_0,\n",
    "        ppsci.loss.MSELoss(\"mean\"),\n",
    "        name=\"Sup_0\",\n",
    "    )\n",
    "\n",
    "    # set equation constarint s.t. ||F(u)||\n",
    "    equation = {\n",
    "        \"NavierStokes\": ppsci.equation.NavierStokes(\n",
    "            nu=1.0 / cfg.re, rho=1.0, dim=2, time=True\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    pde_constraint = ppsci.constraint.InteriorConstraint(\n",
    "        equation[\"NavierStokes\"].equations,\n",
    "        {\"continuity\": 0, \"momentum_x\": 0, \"momentum_y\": 0},\n",
    "        geom,\n",
    "        {\n",
    "            \"dataset\": {\"name\": \"IterableNamedArrayDataset\"},\n",
    "            \"batch_size\": N_TRAIN,\n",
    "            \"iters_per_epoch\": ITERS_PER_EPOCH,\n",
    "        },\n",
    "        ppsci.loss.MSELoss(\"mean\"),\n",
    "        name=\"EQ\",\n",
    "    )\n",
    "\n",
    "    constraint = {\n",
    "        pde_constraint.name: pde_constraint,\n",
    "        sup_constraint_b.name: sup_constraint_b,\n",
    "        sup_constraint_0.name: sup_constraint_0,\n",
    "    }\n",
    "\n",
    "    residual_validator = ppsci.validate.SupervisedValidator(\n",
    "        valida_dataloader_cfg,\n",
    "        ppsci.loss.L2RelLoss(),\n",
    "        metric={\"L2R\": ppsci.metric.L2Rel()},\n",
    "        name=\"Residual\",\n",
    "    )\n",
    "\n",
    "    # wrap validator\n",
    "    validator = {residual_validator.name: residual_validator}\n",
    "\n",
    "    # set optimizer\n",
    "    epoch_list = [5000, 5000, 50000, 50000]\n",
    "    new_epoch_list = []\n",
    "    for i, _ in enumerate(epoch_list):\n",
    "        new_epoch_list.append(sum(epoch_list[: i + 1]))\n",
    "    EPOCHS = new_epoch_list[-1]\n",
    "    lr_list = [1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "    lr_scheduler = ppsci.optimizer.lr_scheduler.Piecewise(\n",
    "        EPOCHS, ITERS_PER_EPOCH, new_epoch_list, lr_list\n",
    "    )()\n",
    "    optimizer = ppsci.optimizer.Adam(lr_scheduler)(model)\n",
    "\n",
    "    logger.init_logger(\"ppsci\", f\"{OUTPUT_DIR}/eval.log\", \"info\")\n",
    "    # initialize solver\n",
    "    solver = ppsci.solver.Solver(\n",
    "        model=model,\n",
    "        constraint=constraint,\n",
    "        optimizer=optimizer,\n",
    "        epochs=EPOCHS,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        iters_per_epoch=ITERS_PER_EPOCH,\n",
    "        eval_during_train=True,\n",
    "        log_freq=cfg.log_freq,\n",
    "        eval_freq=cfg.eval_freq,\n",
    "        seed=SEED,\n",
    "        equation=equation,\n",
    "        geom=geom,\n",
    "        validator=validator,\n",
    "        visualizer=None,\n",
    "        eval_with_no_grad=False,\n",
    "    )\n",
    "    # train model\n",
    "    solver.train()\n",
    "\n",
    "    # evaluate after finished training\n",
    "    solver.eval()\n",
    "\n",
    "    solver.plot_loss_history()\n",
    "\n",
    "\n",
    "def evaluate(cfg: DictConfig):\n",
    "    OUTPUT_DIR = cfg.output_dir\n",
    "    logger.init_logger(\"ppsci\", f\"{OUTPUT_DIR}/train.log\", \"info\")\n",
    "\n",
    "    # set random seed for reproducibility\n",
    "    SEED = cfg.seed\n",
    "    ppsci.utils.misc.set_random_seed(SEED)\n",
    "\n",
    "    # set model\n",
    "    model = ppsci.arch.MLP(**cfg.MODEL)\n",
    "\n",
    "    # set the number of residual samples\n",
    "    N_TRAIN = cfg.ntrain\n",
    "\n",
    "    data = scipy.io.loadmat(cfg.data_dir)\n",
    "\n",
    "    U_star = data[\"U_star\"].astype(\"float32\")  # N x 2 x T\n",
    "    P_star = data[\"p_star\"].astype(\"float32\")  # N x T\n",
    "    t_star = data[\"t\"].astype(\"float32\")  # T x 1\n",
    "    X_star = data[\"X_star\"].astype(\"float32\")  # N x 2\n",
    "\n",
    "    N = X_star.shape[0]\n",
    "    T = t_star.shape[0]\n",
    "\n",
    "    # rearrange data\n",
    "    XX = np.tile(X_star[:, 0:1], (1, T))  # N x T\n",
    "    YY = np.tile(X_star[:, 1:2], (1, T))  # N x T\n",
    "    TT = np.tile(t_star, (1, N)).T  # N x T\n",
    "\n",
    "    UU = U_star[:, 0, :]  # N x T\n",
    "    VV = U_star[:, 1, :]  # N x T\n",
    "    PP = P_star  # N x T\n",
    "\n",
    "    x = XX.flatten()[:, None]  # NT x 1\n",
    "    y = YY.flatten()[:, None]  # NT x 1\n",
    "    t = TT.flatten()[:, None]  # NT x 1\n",
    "\n",
    "    u = UU.flatten()[:, None]  # NT x 1\n",
    "    v = VV.flatten()[:, None]  # NT x 1\n",
    "    p = PP.flatten()[:, None]  # NT x 1\n",
    "\n",
    "    data1 = np.concatenate([x, y, t, u, v, p], 1)\n",
    "    data2 = data1[:, :][data1[:, 2] <= 7]\n",
    "    data3 = data2[:, :][data2[:, 0] >= 1]\n",
    "    data4 = data3[:, :][data3[:, 0] <= 8]\n",
    "    data5 = data4[:, :][data4[:, 1] >= -2]\n",
    "    data_domain = data5[:, :][data5[:, 1] <= 2]\n",
    "\n",
    "    idx = np.random.choice(data_domain.shape[0], N_TRAIN, replace=False)\n",
    "\n",
    "    x_train = data_domain[idx, 0].reshape(data_domain[idx, 0].shape[0], 1)\n",
    "    y_train = data_domain[idx, 1].reshape(data_domain[idx, 1].shape[0], 1)\n",
    "    t_train = data_domain[idx, 2].reshape(data_domain[idx, 2].shape[0], 1)\n",
    "\n",
    "    snap = np.array([0])\n",
    "    x_star = X_star[:, 0:1]\n",
    "    y_star = X_star[:, 1:2]\n",
    "    t_star = TT[:, snap]\n",
    "\n",
    "    u_star = U_star[:, 0, snap]\n",
    "    v_star = U_star[:, 1, snap]\n",
    "    p_star = P_star[:, snap]\n",
    "\n",
    "    valida_dataloader_cfg = {\n",
    "        \"dataset\": {\n",
    "            \"name\": \"NamedArrayDataset\",\n",
    "            \"input\": {\"x\": x_star, \"y\": y_star, \"t\": t_star},\n",
    "            \"label\": {\"u\": u_star, \"v\": v_star, \"p\": p_star},\n",
    "        },\n",
    "        \"total_size\": u_star.shape[0],\n",
    "        \"batch_size\": u_star.shape[0],\n",
    "        \"sampler\": {\n",
    "            \"name\": \"BatchSampler\",\n",
    "            \"drop_last\": False,\n",
    "            \"shuffle\": False,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    geom = ppsci.geometry.PointCloud(\n",
    "        {\"x\": x_train, \"y\": y_train, \"t\": t_train}, (\"x\", \"y\", \"t\")\n",
    "    )\n",
    "\n",
    "    # set equation constarint s.t. ||F(u)||\n",
    "    equation = {\n",
    "        \"NavierStokes\": ppsci.equation.NavierStokes(nu=0.01, rho=1.0, dim=2, time=True),\n",
    "    }\n",
    "\n",
    "    residual_validator = ppsci.validate.SupervisedValidator(\n",
    "        valida_dataloader_cfg,\n",
    "        ppsci.loss.L2RelLoss(),\n",
    "        metric={\"L2R\": ppsci.metric.L2Rel()},\n",
    "        name=\"Residual\",\n",
    "    )\n",
    "\n",
    "    # wrap validator\n",
    "    validator = {residual_validator.name: residual_validator}\n",
    "\n",
    "    solver = ppsci.solver.Solver(\n",
    "        model,\n",
    "        equation=equation,\n",
    "        geom=geom,\n",
    "        validator=validator,\n",
    "        pretrained_model_path=cfg.pretrained_model_path,  ### the path of the model\n",
    "    )\n",
    "\n",
    "    # eval\n",
    "    ## eval validate set\n",
    "    solver.eval()\n",
    "\n",
    "    ## eval every time\n",
    "    us = []\n",
    "    vs = []\n",
    "    for i in range(0, 70):\n",
    "        snap = np.array([i])\n",
    "        x_star = X_star[:, 0:1]\n",
    "        y_star = X_star[:, 1:2]\n",
    "        t_star = TT[:, snap]\n",
    "        u_star = paddle.to_tensor(U_star[:, 0, snap])\n",
    "        v_star = paddle.to_tensor(U_star[:, 1, snap])\n",
    "        p_star = paddle.to_tensor(P_star[:, snap])\n",
    "\n",
    "        solution = solver.predict({\"x\": x_star, \"y\": y_star, \"t\": t_star})\n",
    "        u_pred = solution[\"u\"]\n",
    "        v_pred = solution[\"v\"]\n",
    "        p_pred = solution[\"p\"]\n",
    "        p_pred = p_pred - p_pred.mean() + p_star.mean()\n",
    "        error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
    "        error_v = np.linalg.norm(v_star - v_pred, 2) / np.linalg.norm(v_star, 2)\n",
    "        error_p = np.linalg.norm(p_star - p_pred, 2) / np.linalg.norm(p_star, 2)\n",
    "        us.append(error_u)\n",
    "        vs.append(error_v)\n",
    "        print(\"t={:.2f},relative error of u: {:.3e}\".format(t_star[0].item(), error_u))\n",
    "        print(\"t={:.2f},relative error of v: {:.3e}\".format(t_star[0].item(), error_v))\n",
    "        print(\"t={:.2f},relative error of p: {:.3e}\".format(t_star[0].item(), error_p))\n",
    "\n",
    "    # plot\n",
    "    ## vorticity\n",
    "    grid_x, grid_y = np.mgrid[0.0:8.0:1000j, -2.0:2.0:1000j]\n",
    "    x_star = paddle.to_tensor(grid_x.reshape(-1, 1).astype(\"float32\"))\n",
    "    y_star = paddle.to_tensor(grid_y.reshape(-1, 1).astype(\"float32\"))\n",
    "    t_star = paddle.to_tensor((4.0) * np.ones(x_star.shape).astype(\"float32\"))\n",
    "    x_star.stop_gradient = False\n",
    "    y_star.stop_gradient = False\n",
    "    t_star.stop_gradient = False\n",
    "    sol = model.forward({\"x\": x_star, \"y\": y_star, \"t\": t_star})\n",
    "    u_y = paddle.grad(sol[\"u\"], y_star)\n",
    "    v_x = paddle.grad(sol[\"v\"], x_star)\n",
    "    w = np.array(u_y) - np.array(v_x)\n",
    "    w = w.reshape(1000, 1000)\n",
    "    plt.contour(grid_x, grid_y, w, levels=np.arange(-4, 5, 0.25))\n",
    "    plt.savefig(f\"{OUTPUT_DIR}/vorticity_t=4.png\")\n",
    "\n",
    "    ## relative error\n",
    "    t_snap = []\n",
    "    for i in range(70):\n",
    "        t_snap.append(i / 10)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 3))\n",
    "    ax[0].plot(t_snap, us)\n",
    "    ax[1].plot(t_snap, vs)\n",
    "    ax[0].set_title(\"u\")\n",
    "    ax[1].set_title(\"v\")\n",
    "    fig.savefig(f\"{OUTPUT_DIR}/l2_error.png\")\n",
    "\n",
    "    ## velocity\n",
    "    grid_x, grid_y = np.mgrid[0.0:8.0:1000j, -2.0:2.0:1000j]\n",
    "    for i in range(70):\n",
    "        snap = np.array([i])\n",
    "        x_star = X_star[:, 0:1]\n",
    "        y_star = X_star[:, 1:2]\n",
    "        t_star = TT[:, snap]\n",
    "        points = np.concatenate([x_star, y_star], -1)\n",
    "        u_star = U_star[:, 0, snap]\n",
    "        v_star = U_star[:, 1, snap]\n",
    "\n",
    "        solution = solver.predict({\"x\": x_star, \"y\": y_star, \"t\": t_star})\n",
    "        u_pred = solution[\"u\"]\n",
    "        v_pred = solution[\"v\"]\n",
    "        u_star_ = griddata(points, u_star, (grid_x, grid_y), method=\"cubic\")\n",
    "        u_pred_ = griddata(points, u_pred, (grid_x, grid_y), method=\"cubic\")\n",
    "        v_star_ = griddata(points, v_star, (grid_x, grid_y), method=\"cubic\")\n",
    "        v_pred_ = griddata(points, v_pred, (grid_x, grid_y), method=\"cubic\")\n",
    "        fig, ax = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        ax[0, 0].contourf(grid_x, grid_y, u_star_[:, :, 0])\n",
    "        ax[0, 1].contourf(grid_x, grid_y, u_pred_[:, :, 0])\n",
    "        ax[1, 0].contourf(grid_x, grid_y, v_star_[:, :, 0])\n",
    "        ax[1, 1].contourf(grid_x, grid_y, v_pred_[:, :, 0])\n",
    "        ax[0, 0].set_title(\"u_exact\")\n",
    "        ax[0, 1].set_title(\"u_pred\")\n",
    "        ax[1, 0].set_title(\"v_exact\")\n",
    "        ax[1, 1].set_title(\"v_pred\")\n",
    "        fig.savefig(OUTPUT_DIR + f\"/velocity_t={t_star[i]}.png\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
