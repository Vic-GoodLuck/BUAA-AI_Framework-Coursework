{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- VP_NSFNet1 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import numpy as np\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "import ppsci\n",
    "from ppsci.utils import logger\n",
    "\n",
    "\n",
    "def analytic_solution_generate(x, y, lam):\n",
    "    u = 1 - np.exp(lam * x) * np.cos(2 * np.pi * y)\n",
    "    v = lam / (2 * np.pi) * np.exp(lam * x) * np.sin(2 * np.pi * y)\n",
    "    p = 0.5 * (1 - np.exp(2 * lam * x))\n",
    "    return u, v, p\n",
    "\n",
    "\n",
    "@hydra.main(version_base=None, config_path=\"./conf\", config_name=\"VP_NSFNet1.yaml\")\n",
    "def main(cfg: DictConfig):\n",
    "    if cfg.mode == \"train\":\n",
    "        train(cfg)\n",
    "    elif cfg.mode == \"eval\":\n",
    "        evaluate(cfg)\n",
    "    else:\n",
    "        raise ValueError(f\"cfg.mode should in ['train', 'eval'], but got '{cfg.mode}'\")\n",
    "\n",
    "\n",
    "def generate_data(N_TRAIN, lam, seed):\n",
    "    x = np.linspace(-0.5, 1.0, 101)\n",
    "    y = np.linspace(-0.5, 1.5, 101)\n",
    "\n",
    "    yb1 = np.array([-0.5] * 100)\n",
    "    yb2 = np.array([1] * 100)\n",
    "    xb1 = np.array([-0.5] * 100)\n",
    "    xb2 = np.array([1.5] * 100)\n",
    "\n",
    "    y_train1 = np.concatenate([y[1:101], y[0:100], xb1, xb2], 0).astype(\"float32\")\n",
    "    x_train1 = np.concatenate([yb1, yb2, x[0:100], x[1:101]], 0).astype(\"float32\")\n",
    "\n",
    "    xb_train = x_train1.reshape(x_train1.shape[0], 1).astype(\"float32\")\n",
    "    yb_train = y_train1.reshape(y_train1.shape[0], 1).astype(\"float32\")\n",
    "    ub_train, vb_train, _ = analytic_solution_generate(xb_train, yb_train, lam)\n",
    "\n",
    "    x_train = (np.random.rand(N_TRAIN, 1) - 1 / 3) * 3 / 2\n",
    "    y_train = (np.random.rand(N_TRAIN, 1) - 1 / 4) * 2\n",
    "\n",
    "    # generate test data\n",
    "    np.random.seed(seed)\n",
    "    x_star = ((np.random.rand(1000, 1) - 1 / 3) * 3 / 2).astype(\"float32\")\n",
    "    y_star = ((np.random.rand(1000, 1) - 1 / 4) * 2).astype(\"float32\")\n",
    "\n",
    "    u_star, v_star, p_star = analytic_solution_generate(x_star, y_star, lam)\n",
    "\n",
    "    return (\n",
    "        x_train,\n",
    "        y_train,\n",
    "        xb_train,\n",
    "        yb_train,\n",
    "        ub_train,\n",
    "        vb_train,\n",
    "        x_star,\n",
    "        y_star,\n",
    "        u_star,\n",
    "        v_star,\n",
    "        p_star,\n",
    "    )\n",
    "\n",
    "\n",
    "def train(cfg: DictConfig):\n",
    "    OUTPUT_DIR = cfg.output_dir\n",
    "    logger.init_logger(\"ppsci\", f\"{OUTPUT_DIR}/train.log\", \"info\")\n",
    "\n",
    "    # set random seed for reproducibility\n",
    "    SEED = cfg.seed\n",
    "    ppsci.utils.misc.set_random_seed(SEED)\n",
    "\n",
    "    ITERS_PER_EPOCH = cfg.iters_per_epoch\n",
    "    # set model\n",
    "    model = ppsci.arch.MLP(**cfg.MODEL)\n",
    "\n",
    "    # set the number of residual samples\n",
    "    N_TRAIN = cfg.ntrain\n",
    "\n",
    "    # set the number of boundary samples\n",
    "    NB_TRAIN = cfg.nb_train\n",
    "\n",
    "    # generate data\n",
    "\n",
    "    # set the Reynolds number and the corresponding lambda which is the parameter in the exact solution.\n",
    "    Re = cfg.re\n",
    "    lam = 0.5 * Re - np.sqrt(0.25 * (Re**2) + 4 * (np.pi**2))\n",
    "\n",
    "    (\n",
    "        x_train,\n",
    "        y_train,\n",
    "        xb_train,\n",
    "        yb_train,\n",
    "        ub_train,\n",
    "        vb_train,\n",
    "        x_star,\n",
    "        y_star,\n",
    "        u_star,\n",
    "        v_star,\n",
    "        p_star,\n",
    "    ) = generate_data(N_TRAIN, lam, SEED)\n",
    "\n",
    "    train_dataloader_cfg = {\n",
    "        \"dataset\": {\n",
    "            \"name\": \"NamedArrayDataset\",\n",
    "            \"input\": {\"x\": xb_train, \"y\": yb_train},\n",
    "            \"label\": {\"u\": ub_train, \"v\": vb_train},\n",
    "        },\n",
    "        \"batch_size\": NB_TRAIN,\n",
    "        \"iters_per_epoch\": ITERS_PER_EPOCH,\n",
    "        \"sampler\": {\n",
    "            \"name\": \"BatchSampler\",\n",
    "            \"drop_last\": False,\n",
    "            \"shuffle\": False,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    valida_dataloader_cfg = {\n",
    "        \"dataset\": {\n",
    "            \"name\": \"NamedArrayDataset\",\n",
    "            \"input\": {\"x\": x_star, \"y\": y_star},\n",
    "            \"label\": {\"u\": u_star, \"v\": v_star, \"p\": p_star},\n",
    "        },\n",
    "        \"total_size\": u_star.shape[0],\n",
    "        \"batch_size\": u_star.shape[0],\n",
    "        \"sampler\": {\n",
    "            \"name\": \"BatchSampler\",\n",
    "            \"drop_last\": False,\n",
    "            \"shuffle\": False,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    geom = ppsci.geometry.PointCloud({\"x\": x_train, \"y\": y_train}, (\"x\", \"y\"))\n",
    "\n",
    "    # supervised constraint s.t ||u-u_0||\n",
    "    sup_constraint = ppsci.constraint.SupervisedConstraint(\n",
    "        train_dataloader_cfg,\n",
    "        ppsci.loss.MSELoss(\"mean\"),\n",
    "        name=\"Sup\",\n",
    "    )\n",
    "\n",
    "    # set equation constarint s.t. ||F(u)||\n",
    "    equation = {\n",
    "        \"NavierStokes\": ppsci.equation.NavierStokes(\n",
    "            nu=1.0 / Re, rho=1.0, dim=2, time=False\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    pde_constraint = ppsci.constraint.InteriorConstraint(\n",
    "        equation[\"NavierStokes\"].equations,\n",
    "        {\"continuity\": 0, \"momentum_x\": 0, \"momentum_y\": 0},\n",
    "        geom,\n",
    "        {\n",
    "            \"dataset\": {\"name\": \"IterableNamedArrayDataset\"},\n",
    "            \"batch_size\": N_TRAIN,\n",
    "            \"iters_per_epoch\": ITERS_PER_EPOCH,\n",
    "        },\n",
    "        ppsci.loss.MSELoss(\"mean\"),\n",
    "        name=\"EQ\",\n",
    "    )\n",
    "\n",
    "    constraint = {\n",
    "        sup_constraint.name: sup_constraint,\n",
    "        pde_constraint.name: pde_constraint,\n",
    "    }\n",
    "\n",
    "    residual_validator = ppsci.validate.SupervisedValidator(\n",
    "        valida_dataloader_cfg,\n",
    "        ppsci.loss.L2RelLoss(),\n",
    "        metric={\"L2R\": ppsci.metric.L2Rel()},\n",
    "        name=\"Residual\",\n",
    "    )\n",
    "\n",
    "    # wrap validator\n",
    "    validator = {residual_validator.name: residual_validator}\n",
    "\n",
    "    # set learning rate scheduler\n",
    "    epoch_list = [5000, 5000, 50000, 50000]\n",
    "    new_epoch_list = []\n",
    "    for i, _ in enumerate(epoch_list):\n",
    "        new_epoch_list.append(sum(epoch_list[: i + 1]))\n",
    "    EPOCHS = new_epoch_list[-1]\n",
    "    lr_list = [1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "\n",
    "    lr_scheduler = ppsci.optimizer.lr_scheduler.Piecewise(\n",
    "        EPOCHS, ITERS_PER_EPOCH, new_epoch_list, lr_list\n",
    "    )()\n",
    "\n",
    "    optimizer = ppsci.optimizer.Adam(lr_scheduler)(model)\n",
    "\n",
    "    logger.init_logger(\"ppsci\", f\"{OUTPUT_DIR}/eval.log\", \"info\")\n",
    "\n",
    "    # initialize solver\n",
    "    solver = ppsci.solver.Solver(\n",
    "        model=model,\n",
    "        constraint=constraint,\n",
    "        optimizer=optimizer,\n",
    "        epochs=EPOCHS,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        iters_per_epoch=ITERS_PER_EPOCH,\n",
    "        eval_during_train=False,\n",
    "        log_freq=cfg.log_freq,\n",
    "        eval_freq=cfg.eval_freq,\n",
    "        seed=SEED,\n",
    "        equation=equation,\n",
    "        geom=geom,\n",
    "        validator=validator,\n",
    "        visualizer=None,\n",
    "        eval_with_no_grad=False,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "    )\n",
    "\n",
    "    # train model\n",
    "    solver.train()\n",
    "\n",
    "    solver.eval()\n",
    "\n",
    "    # plot the loss\n",
    "    solver.plot_loss_history()\n",
    "\n",
    "    # set LBFGS optimizer\n",
    "    EPOCHS = 5000\n",
    "    optimizer = ppsci.optimizer.LBFGS(\n",
    "        max_iter=50000, tolerance_change=np.finfo(float).eps, history_size=50\n",
    "    )(model)\n",
    "\n",
    "    logger.init_logger(\"ppsci\", f\"{OUTPUT_DIR}/eval.log\", \"info\")\n",
    "\n",
    "    # initialize solver\n",
    "    solver = ppsci.solver.Solver(\n",
    "        model=model,\n",
    "        constraint=constraint,\n",
    "        optimizer=optimizer,\n",
    "        epochs=EPOCHS,\n",
    "        iters_per_epoch=ITERS_PER_EPOCH,\n",
    "        eval_during_train=False,\n",
    "        log_freq=2000,\n",
    "        eval_freq=2000,\n",
    "        seed=SEED,\n",
    "        equation=equation,\n",
    "        geom=geom,\n",
    "        validator=validator,\n",
    "        visualizer=None,\n",
    "        eval_with_no_grad=False,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "    )\n",
    "    # train model\n",
    "    solver.train()\n",
    "\n",
    "    # evaluate after finished training\n",
    "    solver.eval()\n",
    "\n",
    "\n",
    "def evaluate(cfg: DictConfig):\n",
    "    OUTPUT_DIR = cfg.output_dir\n",
    "    logger.init_logger(\"ppsci\", f\"{OUTPUT_DIR}/train.log\", \"info\")\n",
    "\n",
    "    # set random seed for reproducibility\n",
    "    SEED = cfg.seed\n",
    "    ppsci.utils.misc.set_random_seed(SEED)\n",
    "\n",
    "    # set model\n",
    "    model = ppsci.arch.MLP(**cfg.MODEL)\n",
    "\n",
    "    # set the number of residual samples\n",
    "    N_TRAIN = cfg.ntrain\n",
    "\n",
    "    # set the Reynolds number and the corresponding lambda which is the parameter in the exact solution.\n",
    "    Re = cfg.re\n",
    "    lam = 0.5 * Re - np.sqrt(0.25 * (Re**2) + 4 * (np.pi**2))\n",
    "\n",
    "    x_train = (np.random.rand(N_TRAIN, 1) - 1 / 3) * 3 / 2\n",
    "    y_train = (np.random.rand(N_TRAIN, 1) - 1 / 4) * 2\n",
    "\n",
    "    # generate test data\n",
    "    np.random.seed(SEED)\n",
    "    x_star = ((np.random.rand(1000, 1) - 1 / 3) * 3 / 2).astype(\"float32\")\n",
    "    y_star = ((np.random.rand(1000, 1) - 1 / 4) * 2).astype(\"float32\")\n",
    "    u_star = 1 - np.exp(lam * x_star) * np.cos(2 * np.pi * y_star)\n",
    "    v_star = (lam / (2 * np.pi)) * np.exp(lam * x_star) * np.sin(2 * np.pi * y_star)\n",
    "    p_star = 0.5 * (1 - np.exp(2 * lam * x_star))\n",
    "\n",
    "    valida_dataloader_cfg = {\n",
    "        \"dataset\": {\n",
    "            \"name\": \"NamedArrayDataset\",\n",
    "            \"input\": {\"x\": x_star, \"y\": y_star},\n",
    "            \"label\": {\"u\": u_star, \"v\": v_star, \"p\": p_star},\n",
    "        },\n",
    "        \"total_size\": u_star.shape[0],\n",
    "        \"batch_size\": u_star.shape[0],\n",
    "        \"sampler\": {\n",
    "            \"name\": \"BatchSampler\",\n",
    "            \"drop_last\": False,\n",
    "            \"shuffle\": False,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    geom = ppsci.geometry.PointCloud({\"x\": x_train, \"y\": y_train}, (\"x\", \"y\"))\n",
    "\n",
    "    # set equation constarint s.t. ||F(u)||\n",
    "    equation = {\n",
    "        \"NavierStokes\": ppsci.equation.NavierStokes(\n",
    "            nu=1.0 / Re, rho=1.0, dim=2, time=False\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    residual_validator = ppsci.validate.SupervisedValidator(\n",
    "        valida_dataloader_cfg,\n",
    "        ppsci.loss.L2RelLoss(),\n",
    "        metric={\"L2R\": ppsci.metric.L2Rel()},\n",
    "        name=\"Residual\",\n",
    "    )\n",
    "\n",
    "    # wrap validator\n",
    "    validator = {residual_validator.name: residual_validator}\n",
    "\n",
    "    # load solver\n",
    "    solver = ppsci.solver.Solver(\n",
    "        model,\n",
    "        equation=equation,\n",
    "        geom=geom,\n",
    "        validator=validator,\n",
    "        pretrained_model_path=cfg.pretrained_model_path,  ### the path of the model\n",
    "    )\n",
    "\n",
    "    # eval model\n",
    "    solver.eval()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- VP_NSFNet2 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import paddle\n",
    "import scipy\n",
    "from omegaconf import DictConfig\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "import ppsci\n",
    "from ppsci.utils import logger\n",
    "\n",
    "\n",
    "@hydra.main(version_base=None, config_path=\"./conf\", config_name=\"VP_NSFNet2.yaml\")\n",
    "def main(cfg: DictConfig):\n",
    "    if cfg.mode == \"train\":\n",
    "        train(cfg)\n",
    "    elif cfg.mode == \"eval\":\n",
    "        evaluate(cfg)\n",
    "    else:\n",
    "        raise ValueError(f\"cfg.mode should in ['train', 'eval'], but got '{cfg.mode}'\")\n",
    "\n",
    "\n",
    "def load_data(path, N_TRAIN, NB_TRAIN, N0_TRAIN):\n",
    "    data = scipy.io.loadmat(path)\n",
    "\n",
    "    U_star = data[\"U_star\"].astype(\"float32\")  # N x 2 x T\n",
    "    P_star = data[\"p_star\"].astype(\"float32\")  # N x T\n",
    "    t_star = data[\"t\"].astype(\"float32\")  # T x 1\n",
    "    X_star = data[\"X_star\"].astype(\"float32\")  # N x 2\n",
    "\n",
    "    N = X_star.shape[0]\n",
    "    T = t_star.shape[0]\n",
    "\n",
    "    # rearrange data\n",
    "    XX = np.tile(X_star[:, 0:1], (1, T))  # N x T\n",
    "    YY = np.tile(X_star[:, 1:2], (1, T))  # N x T\n",
    "    TT = np.tile(t_star, (1, N)).T  # N x T\n",
    "\n",
    "    UU = U_star[:, 0, :]  # N x T\n",
    "    VV = U_star[:, 1, :]  # N x T\n",
    "    PP = P_star  # N x T\n",
    "\n",
    "    x = XX.flatten()[:, None]  # NT x 1\n",
    "    y = YY.flatten()[:, None]  # NT x 1\n",
    "    t = TT.flatten()[:, None]  # NT x 1\n",
    "\n",
    "    u = UU.flatten()[:, None]  # NT x 1\n",
    "    v = VV.flatten()[:, None]  # NT x 1\n",
    "    p = PP.flatten()[:, None]  # NT x 1\n",
    "\n",
    "    data1 = np.concatenate([x, y, t, u, v, p], 1)\n",
    "    data2 = data1[:, :][data1[:, 2] <= 7]\n",
    "    data3 = data2[:, :][data2[:, 0] >= 1]\n",
    "    data4 = data3[:, :][data3[:, 0] <= 8]\n",
    "    data5 = data4[:, :][data4[:, 1] >= -2]\n",
    "    data_domain = data5[:, :][data5[:, 1] <= 2]\n",
    "    data_t0 = data_domain[:, :][data_domain[:, 2] == 0]\n",
    "    data_y1 = data_domain[:, :][data_domain[:, 0] == 1]\n",
    "    data_y8 = data_domain[:, :][data_domain[:, 0] == 8]\n",
    "    data_x = data_domain[:, :][data_domain[:, 1] == -2]\n",
    "    data_x2 = data_domain[:, :][data_domain[:, 1] == 2]\n",
    "    data_sup_b_train = np.concatenate([data_y1, data_y8, data_x, data_x2], 0)\n",
    "    idx = np.random.choice(data_domain.shape[0], N_TRAIN, replace=False)\n",
    "\n",
    "    x_train = data_domain[idx, 0].reshape(data_domain[idx, 0].shape[0], 1)\n",
    "    y_train = data_domain[idx, 1].reshape(data_domain[idx, 1].shape[0], 1)\n",
    "    t_train = data_domain[idx, 2].reshape(data_domain[idx, 2].shape[0], 1)\n",
    "\n",
    "    x0_train = data_t0[:, 0].reshape(data_t0[:, 0].shape[0], 1)\n",
    "    y0_train = data_t0[:, 1].reshape(data_t0[:, 1].shape[0], 1)\n",
    "    t0_train = data_t0[:, 2].reshape(data_t0[:, 2].shape[0], 1)\n",
    "    u0_train = data_t0[:, 3].reshape(data_t0[:, 3].shape[0], 1)\n",
    "    v0_train = data_t0[:, 4].reshape(data_t0[:, 4].shape[0], 1)\n",
    "\n",
    "    xb_train = data_sup_b_train[:, 0].reshape(data_sup_b_train[:, 0].shape[0], 1)\n",
    "    yb_train = data_sup_b_train[:, 1].reshape(data_sup_b_train[:, 1].shape[0], 1)\n",
    "    tb_train = data_sup_b_train[:, 2].reshape(data_sup_b_train[:, 2].shape[0], 1)\n",
    "    ub_train = data_sup_b_train[:, 3].reshape(data_sup_b_train[:, 3].shape[0], 1)\n",
    "    vb_train = data_sup_b_train[:, 4].reshape(data_sup_b_train[:, 4].shape[0], 1)\n",
    "\n",
    "    # set test set\n",
    "    snap = np.array([0])\n",
    "    x_star = X_star[:, 0:1]\n",
    "    y_star = X_star[:, 1:2]\n",
    "    t_star = TT[:, snap]\n",
    "\n",
    "    u_star = U_star[:, 0, snap]\n",
    "    v_star = U_star[:, 1, snap]\n",
    "    p_star = P_star[:, snap]\n",
    "\n",
    "    return (\n",
    "        x_train,\n",
    "        y_train,\n",
    "        t_train,\n",
    "        x0_train,\n",
    "        y0_train,\n",
    "        t0_train,\n",
    "        u0_train,\n",
    "        v0_train,\n",
    "        xb_train,\n",
    "        yb_train,\n",
    "        tb_train,\n",
    "        ub_train,\n",
    "        vb_train,\n",
    "        x_star,\n",
    "        y_star,\n",
    "        t_star,\n",
    "        u_star,\n",
    "        v_star,\n",
    "        p_star,\n",
    "    )\n",
    "\n",
    "\n",
    "def train(cfg: DictConfig):\n",
    "    OUTPUT_DIR = cfg.output_dir\n",
    "    logger.init_logger(\"ppsci\", f\"{OUTPUT_DIR}/train.log\", \"info\")\n",
    "\n",
    "    # set random seed for reproducibility\n",
    "    SEED = cfg.seed\n",
    "    ppsci.utils.misc.set_random_seed(SEED)\n",
    "    ITERS_PER_EPOCH = cfg.iters_per_epoch\n",
    "\n",
    "    # set model\n",
    "    model = ppsci.arch.MLP(**cfg.MODEL)\n",
    "\n",
    "    # set the number of residual samples\n",
    "    N_TRAIN = cfg.ntrain\n",
    "\n",
    "    # set the number of boundary samples\n",
    "    NB_TRAIN = cfg.nb_train\n",
    "\n",
    "    # set the number of initial samples\n",
    "    N0_TRAIN = cfg.n0_train\n",
    "\n",
    "    (\n",
    "        x_train,\n",
    "        y_train,\n",
    "        t_train,\n",
    "        x0_train,\n",
    "        y0_train,\n",
    "        t0_train,\n",
    "        u0_train,\n",
    "        v0_train,\n",
    "        xb_train,\n",
    "        yb_train,\n",
    "        tb_train,\n",
    "        ub_train,\n",
    "        vb_train,\n",
    "        x_star,\n",
    "        y_star,\n",
    "        t_star,\n",
    "        u_star,\n",
    "        v_star,\n",
    "        p_star,\n",
    "    ) = load_data(cfg.data_dir, N_TRAIN, NB_TRAIN, N0_TRAIN)\n",
    "    # set dataloader config\n",
    "    train_dataloader_cfg_b = {\n",
    "        \"dataset\": {\n",
    "            \"name\": \"NamedArrayDataset\",\n",
    "            \"input\": {\"x\": xb_train, \"y\": yb_train, \"t\": tb_train},\n",
    "            \"label\": {\"u\": ub_train, \"v\": vb_train},\n",
    "        },\n",
    "        \"batch_size\": NB_TRAIN,\n",
    "        \"iters_per_epoch\": ITERS_PER_EPOCH,\n",
    "        \"sampler\": {\n",
    "            \"name\": \"BatchSampler\",\n",
    "            \"drop_last\": False,\n",
    "            \"shuffle\": False,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    train_dataloader_cfg_0 = {\n",
    "        \"dataset\": {\n",
    "            \"name\": \"NamedArrayDataset\",\n",
    "            \"input\": {\"x\": x0_train, \"y\": y0_train, \"t\": t0_train},\n",
    "            \"label\": {\"u\": u0_train, \"v\": v0_train},\n",
    "        },\n",
    "        \"batch_size\": N0_TRAIN,\n",
    "        \"iters_per_epoch\": ITERS_PER_EPOCH,\n",
    "        \"sampler\": {\n",
    "            \"name\": \"BatchSampler\",\n",
    "            \"drop_last\": False,\n",
    "            \"shuffle\": False,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    valida_dataloader_cfg = {\n",
    "        \"dataset\": {\n",
    "            \"name\": \"NamedArrayDataset\",\n",
    "            \"input\": {\"x\": x_star, \"y\": y_star, \"t\": t_star},\n",
    "            \"label\": {\"u\": u_star, \"v\": v_star, \"p\": p_star},\n",
    "        },\n",
    "        \"total_size\": u_star.shape[0],\n",
    "        \"batch_size\": u_star.shape[0],\n",
    "        \"sampler\": {\n",
    "            \"name\": \"BatchSampler\",\n",
    "            \"drop_last\": False,\n",
    "            \"shuffle\": False,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    geom = ppsci.geometry.PointCloud(\n",
    "        {\"x\": x_train, \"y\": y_train, \"t\": t_train}, (\"x\", \"y\", \"t\")\n",
    "    )\n",
    "\n",
    "    # supervised constraint s.t ||u-u_b||\n",
    "    sup_constraint_b = ppsci.constraint.SupervisedConstraint(\n",
    "        train_dataloader_cfg_b,\n",
    "        ppsci.loss.MSELoss(\"mean\"),\n",
    "        name=\"Sup_b\",\n",
    "    )\n",
    "\n",
    "    # supervised constraint s.t ||u-u_0||\n",
    "    sup_constraint_0 = ppsci.constraint.SupervisedConstraint(\n",
    "        train_dataloader_cfg_0,\n",
    "        ppsci.loss.MSELoss(\"mean\"),\n",
    "        name=\"Sup_0\",\n",
    "    )\n",
    "\n",
    "    # set equation constarint s.t. ||F(u)||\n",
    "    equation = {\n",
    "        \"NavierStokes\": ppsci.equation.NavierStokes(\n",
    "            nu=1.0 / cfg.re, rho=1.0, dim=2, time=True\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    pde_constraint = ppsci.constraint.InteriorConstraint(\n",
    "        equation[\"NavierStokes\"].equations,\n",
    "        {\"continuity\": 0, \"momentum_x\": 0, \"momentum_y\": 0},\n",
    "        geom,\n",
    "        {\n",
    "            \"dataset\": {\"name\": \"IterableNamedArrayDataset\"},\n",
    "            \"batch_size\": N_TRAIN,\n",
    "            \"iters_per_epoch\": ITERS_PER_EPOCH,\n",
    "        },\n",
    "        ppsci.loss.MSELoss(\"mean\"),\n",
    "        name=\"EQ\",\n",
    "    )\n",
    "\n",
    "    constraint = {\n",
    "        pde_constraint.name: pde_constraint,\n",
    "        sup_constraint_b.name: sup_constraint_b,\n",
    "        sup_constraint_0.name: sup_constraint_0,\n",
    "    }\n",
    "\n",
    "    residual_validator = ppsci.validate.SupervisedValidator(\n",
    "        valida_dataloader_cfg,\n",
    "        ppsci.loss.L2RelLoss(),\n",
    "        metric={\"L2R\": ppsci.metric.L2Rel()},\n",
    "        name=\"Residual\",\n",
    "    )\n",
    "\n",
    "    # wrap validator\n",
    "    validator = {residual_validator.name: residual_validator}\n",
    "\n",
    "    # set optimizer\n",
    "    epoch_list = [5000, 5000, 50000, 50000]\n",
    "    new_epoch_list = []\n",
    "    for i, _ in enumerate(epoch_list):\n",
    "        new_epoch_list.append(sum(epoch_list[: i + 1]))\n",
    "    EPOCHS = new_epoch_list[-1]\n",
    "    lr_list = [1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "    lr_scheduler = ppsci.optimizer.lr_scheduler.Piecewise(\n",
    "        EPOCHS, ITERS_PER_EPOCH, new_epoch_list, lr_list\n",
    "    )()\n",
    "    optimizer = ppsci.optimizer.Adam(lr_scheduler)(model)\n",
    "\n",
    "    logger.init_logger(\"ppsci\", f\"{OUTPUT_DIR}/eval.log\", \"info\")\n",
    "    # initialize solver\n",
    "    solver = ppsci.solver.Solver(\n",
    "        model=model,\n",
    "        constraint=constraint,\n",
    "        optimizer=optimizer,\n",
    "        epochs=EPOCHS,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        iters_per_epoch=ITERS_PER_EPOCH,\n",
    "        eval_during_train=True,\n",
    "        log_freq=cfg.log_freq,\n",
    "        eval_freq=cfg.eval_freq,\n",
    "        seed=SEED,\n",
    "        equation=equation,\n",
    "        geom=geom,\n",
    "        validator=validator,\n",
    "        visualizer=None,\n",
    "        eval_with_no_grad=False,\n",
    "    )\n",
    "    # train model\n",
    "    solver.train()\n",
    "\n",
    "    # evaluate after finished training\n",
    "    solver.eval()\n",
    "\n",
    "    solver.plot_loss_history()\n",
    "\n",
    "\n",
    "def evaluate(cfg: DictConfig):\n",
    "    OUTPUT_DIR = cfg.output_dir\n",
    "    logger.init_logger(\"ppsci\", f\"{OUTPUT_DIR}/train.log\", \"info\")\n",
    "\n",
    "    # set random seed for reproducibility\n",
    "    SEED = cfg.seed\n",
    "    ppsci.utils.misc.set_random_seed(SEED)\n",
    "\n",
    "    # set model\n",
    "    model = ppsci.arch.MLP(**cfg.MODEL)\n",
    "\n",
    "    # set the number of residual samples\n",
    "    N_TRAIN = cfg.ntrain\n",
    "\n",
    "    data = scipy.io.loadmat(cfg.data_dir)\n",
    "\n",
    "    U_star = data[\"U_star\"].astype(\"float32\")  # N x 2 x T\n",
    "    P_star = data[\"p_star\"].astype(\"float32\")  # N x T\n",
    "    t_star = data[\"t\"].astype(\"float32\")  # T x 1\n",
    "    X_star = data[\"X_star\"].astype(\"float32\")  # N x 2\n",
    "\n",
    "    N = X_star.shape[0]\n",
    "    T = t_star.shape[0]\n",
    "\n",
    "    # rearrange data\n",
    "    XX = np.tile(X_star[:, 0:1], (1, T))  # N x T\n",
    "    YY = np.tile(X_star[:, 1:2], (1, T))  # N x T\n",
    "    TT = np.tile(t_star, (1, N)).T  # N x T\n",
    "\n",
    "    UU = U_star[:, 0, :]  # N x T\n",
    "    VV = U_star[:, 1, :]  # N x T\n",
    "    PP = P_star  # N x T\n",
    "\n",
    "    x = XX.flatten()[:, None]  # NT x 1\n",
    "    y = YY.flatten()[:, None]  # NT x 1\n",
    "    t = TT.flatten()[:, None]  # NT x 1\n",
    "\n",
    "    u = UU.flatten()[:, None]  # NT x 1\n",
    "    v = VV.flatten()[:, None]  # NT x 1\n",
    "    p = PP.flatten()[:, None]  # NT x 1\n",
    "\n",
    "    data1 = np.concatenate([x, y, t, u, v, p], 1)\n",
    "    data2 = data1[:, :][data1[:, 2] <= 7]\n",
    "    data3 = data2[:, :][data2[:, 0] >= 1]\n",
    "    data4 = data3[:, :][data3[:, 0] <= 8]\n",
    "    data5 = data4[:, :][data4[:, 1] >= -2]\n",
    "    data_domain = data5[:, :][data5[:, 1] <= 2]\n",
    "\n",
    "    idx = np.random.choice(data_domain.shape[0], N_TRAIN, replace=False)\n",
    "\n",
    "    x_train = data_domain[idx, 0].reshape(data_domain[idx, 0].shape[0], 1)\n",
    "    y_train = data_domain[idx, 1].reshape(data_domain[idx, 1].shape[0], 1)\n",
    "    t_train = data_domain[idx, 2].reshape(data_domain[idx, 2].shape[0], 1)\n",
    "\n",
    "    snap = np.array([0])\n",
    "    x_star = X_star[:, 0:1]\n",
    "    y_star = X_star[:, 1:2]\n",
    "    t_star = TT[:, snap]\n",
    "\n",
    "    u_star = U_star[:, 0, snap]\n",
    "    v_star = U_star[:, 1, snap]\n",
    "    p_star = P_star[:, snap]\n",
    "\n",
    "    valida_dataloader_cfg = {\n",
    "        \"dataset\": {\n",
    "            \"name\": \"NamedArrayDataset\",\n",
    "            \"input\": {\"x\": x_star, \"y\": y_star, \"t\": t_star},\n",
    "            \"label\": {\"u\": u_star, \"v\": v_star, \"p\": p_star},\n",
    "        },\n",
    "        \"total_size\": u_star.shape[0],\n",
    "        \"batch_size\": u_star.shape[0],\n",
    "        \"sampler\": {\n",
    "            \"name\": \"BatchSampler\",\n",
    "            \"drop_last\": False,\n",
    "            \"shuffle\": False,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    geom = ppsci.geometry.PointCloud(\n",
    "        {\"x\": x_train, \"y\": y_train, \"t\": t_train}, (\"x\", \"y\", \"t\")\n",
    "    )\n",
    "\n",
    "    # set equation constarint s.t. ||F(u)||\n",
    "    equation = {\n",
    "        \"NavierStokes\": ppsci.equation.NavierStokes(nu=0.01, rho=1.0, dim=2, time=True),\n",
    "    }\n",
    "\n",
    "    residual_validator = ppsci.validate.SupervisedValidator(\n",
    "        valida_dataloader_cfg,\n",
    "        ppsci.loss.L2RelLoss(),\n",
    "        metric={\"L2R\": ppsci.metric.L2Rel()},\n",
    "        name=\"Residual\",\n",
    "    )\n",
    "\n",
    "    # wrap validator\n",
    "    validator = {residual_validator.name: residual_validator}\n",
    "\n",
    "    solver = ppsci.solver.Solver(\n",
    "        model,\n",
    "        equation=equation,\n",
    "        geom=geom,\n",
    "        validator=validator,\n",
    "        pretrained_model_path=cfg.pretrained_model_path,  ### the path of the model\n",
    "    )\n",
    "\n",
    "    # eval\n",
    "    ## eval validate set\n",
    "    solver.eval()\n",
    "\n",
    "    ## eval every time\n",
    "    us = []\n",
    "    vs = []\n",
    "    for i in range(0, 70):\n",
    "        snap = np.array([i])\n",
    "        x_star = X_star[:, 0:1]\n",
    "        y_star = X_star[:, 1:2]\n",
    "        t_star = TT[:, snap]\n",
    "        u_star = paddle.to_tensor(U_star[:, 0, snap])\n",
    "        v_star = paddle.to_tensor(U_star[:, 1, snap])\n",
    "        p_star = paddle.to_tensor(P_star[:, snap])\n",
    "\n",
    "        solution = solver.predict({\"x\": x_star, \"y\": y_star, \"t\": t_star})\n",
    "        u_pred = solution[\"u\"]\n",
    "        v_pred = solution[\"v\"]\n",
    "        p_pred = solution[\"p\"]\n",
    "        p_pred = p_pred - p_pred.mean() + p_star.mean()\n",
    "        error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
    "        error_v = np.linalg.norm(v_star - v_pred, 2) / np.linalg.norm(v_star, 2)\n",
    "        error_p = np.linalg.norm(p_star - p_pred, 2) / np.linalg.norm(p_star, 2)\n",
    "        us.append(error_u)\n",
    "        vs.append(error_v)\n",
    "        print(\"t={:.2f},relative error of u: {:.3e}\".format(t_star[0].item(), error_u))\n",
    "        print(\"t={:.2f},relative error of v: {:.3e}\".format(t_star[0].item(), error_v))\n",
    "        print(\"t={:.2f},relative error of p: {:.3e}\".format(t_star[0].item(), error_p))\n",
    "\n",
    "    # plot\n",
    "    ## vorticity\n",
    "    grid_x, grid_y = np.mgrid[0.0:8.0:1000j, -2.0:2.0:1000j]\n",
    "    x_star = paddle.to_tensor(grid_x.reshape(-1, 1).astype(\"float32\"))\n",
    "    y_star = paddle.to_tensor(grid_y.reshape(-1, 1).astype(\"float32\"))\n",
    "    t_star = paddle.to_tensor((4.0) * np.ones(x_star.shape).astype(\"float32\"))\n",
    "    x_star.stop_gradient = False\n",
    "    y_star.stop_gradient = False\n",
    "    t_star.stop_gradient = False\n",
    "    sol = model.forward({\"x\": x_star, \"y\": y_star, \"t\": t_star})\n",
    "    u_y = paddle.grad(sol[\"u\"], y_star)\n",
    "    v_x = paddle.grad(sol[\"v\"], x_star)\n",
    "    w = np.array(u_y) - np.array(v_x)\n",
    "    w = w.reshape(1000, 1000)\n",
    "    plt.contour(grid_x, grid_y, w, levels=np.arange(-4, 5, 0.25))\n",
    "    plt.savefig(f\"{OUTPUT_DIR}/vorticity_t=4.png\")\n",
    "\n",
    "    ## relative error\n",
    "    t_snap = []\n",
    "    for i in range(70):\n",
    "        t_snap.append(i / 10)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 3))\n",
    "    ax[0].plot(t_snap, us)\n",
    "    ax[1].plot(t_snap, vs)\n",
    "    ax[0].set_title(\"u\")\n",
    "    ax[1].set_title(\"v\")\n",
    "    fig.savefig(f\"{OUTPUT_DIR}/l2_error.png\")\n",
    "\n",
    "    ## velocity\n",
    "    grid_x, grid_y = np.mgrid[0.0:8.0:1000j, -2.0:2.0:1000j]\n",
    "    for i in range(70):\n",
    "        snap = np.array([i])\n",
    "        x_star = X_star[:, 0:1]\n",
    "        y_star = X_star[:, 1:2]\n",
    "        t_star = TT[:, snap]\n",
    "        points = np.concatenate([x_star, y_star], -1)\n",
    "        u_star = U_star[:, 0, snap]\n",
    "        v_star = U_star[:, 1, snap]\n",
    "\n",
    "        solution = solver.predict({\"x\": x_star, \"y\": y_star, \"t\": t_star})\n",
    "        u_pred = solution[\"u\"]\n",
    "        v_pred = solution[\"v\"]\n",
    "        u_star_ = griddata(points, u_star, (grid_x, grid_y), method=\"cubic\")\n",
    "        u_pred_ = griddata(points, u_pred, (grid_x, grid_y), method=\"cubic\")\n",
    "        v_star_ = griddata(points, v_star, (grid_x, grid_y), method=\"cubic\")\n",
    "        v_pred_ = griddata(points, v_pred, (grid_x, grid_y), method=\"cubic\")\n",
    "        fig, ax = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        ax[0, 0].contourf(grid_x, grid_y, u_star_[:, :, 0])\n",
    "        ax[0, 1].contourf(grid_x, grid_y, u_pred_[:, :, 0])\n",
    "        ax[1, 0].contourf(grid_x, grid_y, v_star_[:, :, 0])\n",
    "        ax[1, 1].contourf(grid_x, grid_y, v_pred_[:, :, 0])\n",
    "        ax[0, 0].set_title(\"u_exact\")\n",
    "        ax[0, 1].set_title(\"u_pred\")\n",
    "        ax[1, 0].set_title(\"v_exact\")\n",
    "        ax[1, 1].set_title(\"v_pred\")\n",
    "        fig.savefig(OUTPUT_DIR + f\"/velocity_t={t_star[i]}.png\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- VP_NSFNet3 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "import ppsci\n",
    "from ppsci.utils import logger\n",
    "\n",
    "\n",
    "def analytic_solution_generate(x, y, z, t):\n",
    "    a, d = 1, 1\n",
    "    u = (\n",
    "        -a\n",
    "        * (\n",
    "            np.exp(a * x) * np.sin(a * y + d * z)\n",
    "            + np.exp(a * z) * np.cos(a * x + d * y)\n",
    "        )\n",
    "        * np.exp(-d * d * t)\n",
    "    )\n",
    "    v = (\n",
    "        -a\n",
    "        * (\n",
    "            np.exp(a * y) * np.sin(a * z + d * x)\n",
    "            + np.exp(a * x) * np.cos(a * y + d * z)\n",
    "        )\n",
    "        * np.exp(-d * d * t)\n",
    "    )\n",
    "    w = (\n",
    "        -a\n",
    "        * (\n",
    "            np.exp(a * z) * np.sin(a * x + d * y)\n",
    "            + np.exp(a * y) * np.cos(a * z + d * x)\n",
    "        )\n",
    "        * np.exp(-d * d * t)\n",
    "    )\n",
    "    p = (\n",
    "        -0.5\n",
    "        * a\n",
    "        * a\n",
    "        * (\n",
    "            np.exp(2 * a * x)\n",
    "            + np.exp(2 * a * y)\n",
    "            + np.exp(2 * a * z)\n",
    "            + 2 * np.sin(a * x + d * y) * np.cos(a * z + d * x) * np.exp(a * (y + z))\n",
    "            + 2 * np.sin(a * y + d * z) * np.cos(a * x + d * y) * np.exp(a * (z + x))\n",
    "            + 2 * np.sin(a * z + d * x) * np.cos(a * y + d * z) * np.exp(a * (x + y))\n",
    "        )\n",
    "        * np.exp(-2 * d * d * t)\n",
    "    )\n",
    "\n",
    "    return u, v, w, p\n",
    "\n",
    "\n",
    "def generate_data(N_TRAIN):\n",
    "    # generate boundary data\n",
    "    x1 = np.linspace(-1, 1, 31)\n",
    "    y1 = np.linspace(-1, 1, 31)\n",
    "    z1 = np.linspace(-1, 1, 31)\n",
    "    t1 = np.linspace(0, 1, 11)\n",
    "    b0 = np.array([-1] * 900)\n",
    "    b1 = np.array([1] * 900)\n",
    "\n",
    "    xt = np.tile(x1[0:30], 30)\n",
    "    yt = np.tile(y1[0:30], 30)\n",
    "    xt1 = np.tile(x1[1:31], 30)\n",
    "    yt1 = np.tile(y1[1:31], 30)\n",
    "\n",
    "    yr = y1[0:30].repeat(30)\n",
    "    zr = z1[0:30].repeat(30)\n",
    "    yr1 = y1[1:31].repeat(30)\n",
    "    zr1 = z1[1:31].repeat(30)\n",
    "\n",
    "    train1x = np.concatenate([b1, b0, xt1, xt, xt1, xt], 0).repeat(t1.shape[0])\n",
    "    train1y = np.concatenate([yt, yt1, b1, b0, yr1, yr], 0).repeat(t1.shape[0])\n",
    "    train1z = np.concatenate([zr, zr1, zr, zr1, b1, b0], 0).repeat(t1.shape[0])\n",
    "    train1t = np.tile(t1, 5400)\n",
    "\n",
    "    train1ub, train1vb, train1wb, train1pb = analytic_solution_generate(\n",
    "        train1x, train1y, train1z, train1t\n",
    "    )\n",
    "\n",
    "    xb_train = train1x.reshape(train1x.shape[0], 1).astype(\"float32\")\n",
    "    yb_train = train1y.reshape(train1y.shape[0], 1).astype(\"float32\")\n",
    "    zb_train = train1z.reshape(train1z.shape[0], 1).astype(\"float32\")\n",
    "    tb_train = train1t.reshape(train1t.shape[0], 1).astype(\"float32\")\n",
    "    ub_train = train1ub.reshape(train1ub.shape[0], 1).astype(\"float32\")\n",
    "    vb_train = train1vb.reshape(train1vb.shape[0], 1).astype(\"float32\")\n",
    "    wb_train = train1wb.reshape(train1wb.shape[0], 1).astype(\"float32\")\n",
    "\n",
    "    # generate initial data\n",
    "    x_0 = np.tile(x1, 31 * 31)\n",
    "    y_0 = np.tile(y1.repeat(31), 31)\n",
    "    z_0 = z1.repeat(31 * 31)\n",
    "    t_0 = np.array([0] * x_0.shape[0])\n",
    "    u_0, v_0, w_0, p_0 = analytic_solution_generate(x_0, y_0, z_0, t_0)\n",
    "    u0_train = u_0.reshape(u_0.shape[0], 1).astype(\"float32\")\n",
    "    v0_train = v_0.reshape(v_0.shape[0], 1).astype(\"float32\")\n",
    "    w0_train = w_0.reshape(w_0.shape[0], 1).astype(\"float32\")\n",
    "    x0_train = x_0.reshape(x_0.shape[0], 1).astype(\"float32\")\n",
    "    y0_train = y_0.reshape(y_0.shape[0], 1).astype(\"float32\")\n",
    "    z0_train = z_0.reshape(z_0.shape[0], 1).astype(\"float32\")\n",
    "    t0_train = t_0.reshape(t_0.shape[0], 1).astype(\"float32\")\n",
    "\n",
    "    # unsupervised part\n",
    "    xx = np.random.randint(31, size=N_TRAIN) / 15 - 1\n",
    "    yy = np.random.randint(31, size=N_TRAIN) / 15 - 1\n",
    "    zz = np.random.randint(31, size=N_TRAIN) / 15 - 1\n",
    "    tt = np.random.randint(11, size=N_TRAIN) / 10\n",
    "\n",
    "    x_train = xx.reshape(xx.shape[0], 1).astype(\"float32\")\n",
    "    y_train = yy.reshape(yy.shape[0], 1).astype(\"float32\")\n",
    "    z_train = zz.reshape(zz.shape[0], 1).astype(\"float32\")\n",
    "    t_train = tt.reshape(tt.shape[0], 1).astype(\"float32\")\n",
    "\n",
    "    # test data\n",
    "    x_star = ((np.random.rand(1000, 1) - 1 / 2) * 2).astype(\"float32\")\n",
    "    y_star = ((np.random.rand(1000, 1) - 1 / 2) * 2).astype(\"float32\")\n",
    "    z_star = ((np.random.rand(1000, 1) - 1 / 2) * 2).astype(\"float32\")\n",
    "    t_star = (np.random.randint(11, size=(1000, 1)) / 10).astype(\"float32\")\n",
    "\n",
    "    u_star, v_star, w_star, p_star = analytic_solution_generate(\n",
    "        x_star, y_star, z_star, t_star\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        x_train,\n",
    "        y_train,\n",
    "        z_train,\n",
    "        t_train,\n",
    "        x0_train,\n",
    "        y0_train,\n",
    "        z0_train,\n",
    "        t0_train,\n",
    "        u0_train,\n",
    "        v0_train,\n",
    "        w0_train,\n",
    "        xb_train,\n",
    "        yb_train,\n",
    "        zb_train,\n",
    "        tb_train,\n",
    "        ub_train,\n",
    "        vb_train,\n",
    "        wb_train,\n",
    "        x_star,\n",
    "        y_star,\n",
    "        z_star,\n",
    "        t_star,\n",
    "        u_star,\n",
    "        v_star,\n",
    "        w_star,\n",
    "        p_star,\n",
    "    )\n",
    "\n",
    "\n",
    "@hydra.main(version_base=None, config_path=\"./conf\", config_name=\"VP_NSFNet3.yaml\")\n",
    "def main(cfg: DictConfig):\n",
    "    if cfg.mode == \"train\":\n",
    "        train(cfg)\n",
    "    elif cfg.mode == \"eval\":\n",
    "        evaluate(cfg)\n",
    "    else:\n",
    "        raise ValueError(f\"cfg.mode should in ['train', 'eval'], but got '{cfg.mode}'\")\n",
    "\n",
    "\n",
    "def train(cfg: DictConfig):\n",
    "    OUTPUT_DIR = cfg.output_dir\n",
    "    logger.init_logger(\"ppsci\", f\"{OUTPUT_DIR}/train.log\", \"info\")\n",
    "\n",
    "    # set random seed for reproducibility\n",
    "    SEED = cfg.seed\n",
    "    ppsci.utils.misc.set_random_seed(SEED)\n",
    "    ITERS_PER_EPOCH = cfg.iters_per_epoch\n",
    "\n",
    "    # set model\n",
    "    model = ppsci.arch.MLP(**cfg.MODEL)\n",
    "\n",
    "    # set the number of residual samples\n",
    "    N_TRAIN = cfg.ntrain\n",
    "\n",
    "    # set the number of boundary samples\n",
    "    NB_TRAIN = cfg.nb_train\n",
    "\n",
    "    # set the number of initial samples\n",
    "    N0_TRAIN = cfg.n0_train\n",
    "    ALPHA = cfg.alpha\n",
    "    BETA = cfg.beta\n",
    "    (\n",
    "        x_train,\n",
    "        y_train,\n",
    "        z_train,\n",
    "        t_train,\n",
    "        x0_train,\n",
    "        y0_train,\n",
    "        z0_train,\n",
    "        t0_train,\n",
    "        u0_train,\n",
    "        v0_train,\n",
    "        w0_train,\n",
    "        xb_train,\n",
    "        yb_train,\n",
    "        zb_train,\n",
    "        tb_train,\n",
    "        ub_train,\n",
    "        vb_train,\n",
    "        wb_train,\n",
    "        x_star,\n",
    "        y_star,\n",
    "        z_star,\n",
    "        t_star,\n",
    "        u_star,\n",
    "        v_star,\n",
    "        w_star,\n",
    "        p_star,\n",
    "    ) = generate_data(N_TRAIN)\n",
    "\n",
    "    # set dataloader config\n",
    "    train_dataloader_cfg_b = {\n",
    "        \"dataset\": {\n",
    "            \"name\": \"NamedArrayDataset\",\n",
    "            \"input\": {\"x\": xb_train, \"y\": yb_train, \"z\": zb_train, \"t\": tb_train},\n",
    "            \"label\": {\"u\": ub_train, \"v\": vb_train, \"w\": wb_train},\n",
    "        },\n",
    "        \"batch_size\": NB_TRAIN,\n",
    "        \"iters_per_epoch\": ITERS_PER_EPOCH,\n",
    "        \"sampler\": {\n",
    "            \"name\": \"BatchSampler\",\n",
    "            \"drop_last\": False,\n",
    "            \"shuffle\": False,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    train_dataloader_cfg_0 = {\n",
    "        \"dataset\": {\n",
    "            \"name\": \"NamedArrayDataset\",\n",
    "            \"input\": {\"x\": x0_train, \"y\": y0_train, \"z\": z0_train, \"t\": t0_train},\n",
    "            \"label\": {\"u\": u0_train, \"v\": v0_train, \"w\": w0_train},\n",
    "        },\n",
    "        \"batch_size\": N0_TRAIN,\n",
    "        \"iters_per_epoch\": ITERS_PER_EPOCH,\n",
    "        \"sampler\": {\n",
    "            \"name\": \"BatchSampler\",\n",
    "            \"drop_last\": False,\n",
    "            \"shuffle\": False,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    valida_dataloader_cfg = {\n",
    "        \"dataset\": {\n",
    "            \"name\": \"NamedArrayDataset\",\n",
    "            \"input\": {\"x\": x_star, \"y\": y_star, \"z\": z_star, \"t\": t_star},\n",
    "            \"label\": {\"u\": u_star, \"v\": v_star, \"w\": w_star, \"p\": p_star},\n",
    "        },\n",
    "        \"total_size\": u_star.shape[0],\n",
    "        \"batch_size\": u_star.shape[0],\n",
    "        \"sampler\": {\n",
    "            \"name\": \"BatchSampler\",\n",
    "            \"drop_last\": False,\n",
    "            \"shuffle\": False,\n",
    "        },\n",
    "    }\n",
    "    geom = ppsci.geometry.PointCloud(\n",
    "        {\"x\": x_train, \"y\": y_train, \"z\": z_train, \"t\": t_train}, (\"x\", \"y\", \"z\", \"t\")\n",
    "    )\n",
    "\n",
    "    # supervised constraint s.t ||u-u_b||\n",
    "    sup_constraint_b = ppsci.constraint.SupervisedConstraint(\n",
    "        train_dataloader_cfg_b,\n",
    "        ppsci.loss.MSELoss(\"mean\", ALPHA),\n",
    "        name=\"Sup_b\",\n",
    "    )\n",
    "\n",
    "    # supervised constraint s.t ||u-u_0||\n",
    "    sup_constraint_0 = ppsci.constraint.SupervisedConstraint(\n",
    "        train_dataloader_cfg_0,\n",
    "        ppsci.loss.MSELoss(\"mean\", BETA),\n",
    "        name=\"Sup_0\",\n",
    "    )\n",
    "\n",
    "    # set equation constarint s.t. ||F(u)||\n",
    "    equation = {\n",
    "        \"NavierStokes\": ppsci.equation.NavierStokes(\n",
    "            nu=1.0 / cfg.re, rho=1.0, dim=3, time=True\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    pde_constraint = ppsci.constraint.InteriorConstraint(\n",
    "        equation[\"NavierStokes\"].equations,\n",
    "        {\"continuity\": 0, \"momentum_x\": 0, \"momentum_y\": 0, \"momentum_z\": 0},\n",
    "        geom,\n",
    "        {\n",
    "            \"dataset\": {\"name\": \"IterableNamedArrayDataset\"},\n",
    "            \"batch_size\": N_TRAIN,\n",
    "            \"iters_per_epoch\": ITERS_PER_EPOCH,\n",
    "        },\n",
    "        ppsci.loss.MSELoss(\"mean\"),\n",
    "        name=\"EQ\",\n",
    "    )\n",
    "\n",
    "    # wrap constraint\n",
    "    constraint = {\n",
    "        pde_constraint.name: pde_constraint,\n",
    "        sup_constraint_b.name: sup_constraint_b,\n",
    "        sup_constraint_0.name: sup_constraint_0,\n",
    "    }\n",
    "\n",
    "    residual_validator = ppsci.validate.SupervisedValidator(\n",
    "        valida_dataloader_cfg,\n",
    "        ppsci.loss.L2RelLoss(),\n",
    "        metric={\"L2R\": ppsci.metric.L2Rel()},\n",
    "        name=\"Residual\",\n",
    "    )\n",
    "\n",
    "    # wrap validator\n",
    "    validator = {residual_validator.name: residual_validator}\n",
    "\n",
    "    # set optimizer\n",
    "    epoch_list = [5000, 5000, 50000, 50000]\n",
    "    new_epoch_list = []\n",
    "    for i, _ in enumerate(epoch_list):\n",
    "        new_epoch_list.append(sum(epoch_list[: i + 1]))\n",
    "    EPOCHS = new_epoch_list[-1]\n",
    "    lr_list = [1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "    lr_scheduler = ppsci.optimizer.lr_scheduler.Piecewise(\n",
    "        EPOCHS, ITERS_PER_EPOCH, new_epoch_list, lr_list\n",
    "    )()\n",
    "    optimizer = ppsci.optimizer.Adam(lr_scheduler)(model)\n",
    "    logger.init_logger(\"ppsci\", f\"{OUTPUT_DIR}/eval.log\", \"info\")\n",
    "    # initialize solver\n",
    "    solver = ppsci.solver.Solver(\n",
    "        model=model,\n",
    "        constraint=constraint,\n",
    "        optimizer=optimizer,\n",
    "        epochs=EPOCHS,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        iters_per_epoch=ITERS_PER_EPOCH,\n",
    "        eval_during_train=True,\n",
    "        log_freq=cfg.log_freq,\n",
    "        eval_freq=cfg.eval_freq,\n",
    "        seed=SEED,\n",
    "        equation=equation,\n",
    "        geom=geom,\n",
    "        validator=validator,\n",
    "        visualizer=None,\n",
    "        eval_with_no_grad=False,\n",
    "    )\n",
    "    # train model\n",
    "    solver.train()\n",
    "\n",
    "    # evaluate after finished training\n",
    "    solver.eval()\n",
    "    solver.plot_loss_history()\n",
    "\n",
    "\n",
    "def evaluate(cfg: DictConfig):\n",
    "    OUTPUT_DIR = cfg.output_dir\n",
    "    logger.init_logger(\"ppsci\", f\"{OUTPUT_DIR}/train.log\", \"info\")\n",
    "\n",
    "    # set random seed for reproducibility\n",
    "    SEED = cfg.seed\n",
    "    ppsci.utils.misc.set_random_seed(SEED)\n",
    "\n",
    "    # set model\n",
    "    model = ppsci.arch.MLP(**cfg.MODEL)\n",
    "\n",
    "    # set the number of residual samples\n",
    "    N_TRAIN = cfg.ntrain\n",
    "\n",
    "    # unsupervised part\n",
    "    xx = np.random.randint(31, size=N_TRAIN) / 15 - 1\n",
    "    yy = np.random.randint(31, size=N_TRAIN) / 15 - 1\n",
    "    zz = np.random.randint(31, size=N_TRAIN) / 15 - 1\n",
    "    tt = np.random.randint(11, size=N_TRAIN) / 10\n",
    "\n",
    "    x_train = xx.reshape(xx.shape[0], 1).astype(\"float32\")\n",
    "    y_train = yy.reshape(yy.shape[0], 1).astype(\"float32\")\n",
    "    z_train = zz.reshape(zz.shape[0], 1).astype(\"float32\")\n",
    "    t_train = tt.reshape(tt.shape[0], 1).astype(\"float32\")\n",
    "\n",
    "    # test data\n",
    "    x_star = ((np.random.rand(1000, 1) - 1 / 2) * 2).astype(\"float32\")\n",
    "    y_star = ((np.random.rand(1000, 1) - 1 / 2) * 2).astype(\"float32\")\n",
    "    z_star = ((np.random.rand(1000, 1) - 1 / 2) * 2).astype(\"float32\")\n",
    "    t_star = (np.random.randint(11, size=(1000, 1)) / 10).astype(\"float32\")\n",
    "\n",
    "    u_star, v_star, w_star, p_star = analytic_solution_generate(\n",
    "        x_star, y_star, z_star, t_star\n",
    "    )\n",
    "\n",
    "    valida_dataloader_cfg = {\n",
    "        \"dataset\": {\n",
    "            \"name\": \"NamedArrayDataset\",\n",
    "            \"input\": {\"x\": x_star, \"y\": y_star, \"z\": z_star, \"t\": t_star},\n",
    "            \"label\": {\"u\": u_star, \"v\": v_star, \"w\": w_star, \"p\": p_star},\n",
    "        },\n",
    "        \"total_size\": u_star.shape[0],\n",
    "        \"batch_size\": u_star.shape[0],\n",
    "        \"sampler\": {\n",
    "            \"name\": \"BatchSampler\",\n",
    "            \"drop_last\": False,\n",
    "            \"shuffle\": False,\n",
    "        },\n",
    "    }\n",
    "    geom = ppsci.geometry.PointCloud(\n",
    "        {\"x\": x_train, \"y\": y_train, \"z\": z_train, \"t\": t_train}, (\"x\", \"y\", \"z\", \"t\")\n",
    "    )\n",
    "\n",
    "    equation = {\n",
    "        \"NavierStokes\": ppsci.equation.NavierStokes(\n",
    "            nu=1.0 / cfg.re, rho=1.0, dim=3, time=True\n",
    "        ),\n",
    "    }\n",
    "    residual_validator = ppsci.validate.SupervisedValidator(\n",
    "        valida_dataloader_cfg,\n",
    "        ppsci.loss.L2RelLoss(),\n",
    "        metric={\"L2R\": ppsci.metric.L2Rel()},\n",
    "        name=\"Residual\",\n",
    "    )\n",
    "\n",
    "    # wrap validator\n",
    "    validator = {residual_validator.name: residual_validator}\n",
    "\n",
    "    # load solver\n",
    "    solver = ppsci.solver.Solver(\n",
    "        model,\n",
    "        equation=equation,\n",
    "        geom=geom,\n",
    "        validator=validator,\n",
    "        pretrained_model_path=cfg.pretrained_model_path,  ### the path of the model\n",
    "    )\n",
    "\n",
    "    # print the relative error\n",
    "    us = []\n",
    "    vs = []\n",
    "    ws = []\n",
    "    for i in [0, 0.25, 0.5, 0.75, 1.0]:\n",
    "        x_star, y_star, z_star = np.mgrid[-1.0:1.0:100j, -1.0:1.0:100j, -1.0:1.0:100j]\n",
    "        x_star, y_star, z_star = (\n",
    "            x_star.reshape(-1, 1),\n",
    "            y_star.reshape(-1, 1),\n",
    "            z_star.reshape(-1, 1),\n",
    "        )\n",
    "        t_star = i * np.ones(x_star.shape)\n",
    "        u_star, v_star, w_star, p_star = analytic_solution_generate(\n",
    "            x_star, y_star, z_star, t_star\n",
    "        )\n",
    "\n",
    "        ##\n",
    "        x_star = x_star.astype(\"float32\")\n",
    "        y_star = y_star.astype(\"float32\")\n",
    "        z_star = z_star.astype(\"float32\")\n",
    "        t_star = t_star.astype(\"float32\")\n",
    "        ##\n",
    "\n",
    "        solution = solver.predict({\"x\": x_star, \"y\": y_star, \"z\": z_star, \"t\": t_star})\n",
    "        u_pred = solution[\"u\"]\n",
    "        v_pred = solution[\"v\"]\n",
    "        w_pred = solution[\"w\"]\n",
    "        p_pred = solution[\"p\"]\n",
    "        p_pred = p_pred - p_pred.mean() + p_star.mean()\n",
    "        error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
    "        error_v = np.linalg.norm(v_star - v_pred, 2) / np.linalg.norm(v_star, 2)\n",
    "        error_w = np.linalg.norm(w_star - w_pred, 2) / np.linalg.norm(w_star, 2)\n",
    "        error_p = np.linalg.norm(p_star - p_pred, 2) / np.linalg.norm(p_star, 2)\n",
    "        us.append(error_u)\n",
    "        vs.append(error_v)\n",
    "        ws.append(error_w)\n",
    "        print(\"t={:.2f},relative error of u: {:.3e}\".format(t_star[0].item(), error_u))\n",
    "        print(\"t={:.2f},relative error of v: {:.3e}\".format(t_star[0].item(), error_v))\n",
    "        print(\"t={:.2f},relative error of w: {:.3e}\".format(t_star[0].item(), error_w))\n",
    "        print(\"t={:.2f},relative error of p: {:.3e}\".format(t_star[0].item(), error_p))\n",
    "\n",
    "    ## plot vorticity\n",
    "    grid_x, grid_y = np.mgrid[-1.0:1.0:1000j, -1.0:1.0:1000j]\n",
    "    grid_x = grid_x.reshape(-1, 1)\n",
    "    grid_y = grid_y.reshape(-1, 1)\n",
    "    grid_z = np.zeros(grid_x.shape)\n",
    "    T = np.linspace(0, 1, 20)\n",
    "    for i in T:\n",
    "        t_star = i * np.ones(x_star.shape)\n",
    "        u_star, v_star, w_star, p_star = analytic_solution_generate(\n",
    "            grid_x, grid_y, grid_z, t_star\n",
    "        )\n",
    "\n",
    "        ##\n",
    "        grid_x = x_star.astype(\"float32\")\n",
    "        grid_y = y_star.astype(\"float32\")\n",
    "        grid_z = z_star.astype(\"float32\")\n",
    "        t_star = t_star.astype(\"float32\")\n",
    "        ##\n",
    "\n",
    "        solution = solver.predict({\"x\": grid_x, \"y\": grid_y, \"z\": grid_z, \"t\": t_star})\n",
    "        u_pred = np.array(solution[\"u\"])\n",
    "        v_pred = np.array(solution[\"v\"])\n",
    "        w_pred = np.array(solution[\"w\"])\n",
    "        p_pred = p_pred - p_pred.mean() + p_star.mean()\n",
    "        fig, ax = plt.subplots(3, 2, figsize=(12, 12))\n",
    "        ax[0, 0].contourf(\n",
    "            grid_x.reshape(1000, 1000),\n",
    "            grid_y.reshape(1000, 1000),\n",
    "            u_star.reshape(1000, 1000),\n",
    "            cmap=plt.get_cmap(\"RdYlBu\"),\n",
    "        )\n",
    "        ax[0, 1].contourf(\n",
    "            grid_x.reshape(1000, 1000),\n",
    "            grid_y.reshape(1000, 1000),\n",
    "            u_pred.reshape(1000, 1000),\n",
    "            cmap=plt.get_cmap(\"RdYlBu\"),\n",
    "        )\n",
    "        ax[1, 0].contourf(\n",
    "            grid_x.reshape(1000, 1000),\n",
    "            grid_y.reshape(1000, 1000),\n",
    "            v_star.reshape(1000, 1000),\n",
    "            cmap=plt.get_cmap(\"RdYlBu\"),\n",
    "        )\n",
    "        ax[1, 1].contourf(\n",
    "            grid_x.reshape(1000, 1000),\n",
    "            grid_y.reshape(1000, 1000),\n",
    "            v_pred.reshape(1000, 1000),\n",
    "            cmap=plt.get_cmap(\"RdYlBu\"),\n",
    "        )\n",
    "        ax[2, 0].contourf(\n",
    "            grid_x.reshape(1000, 1000),\n",
    "            grid_y.reshape(1000, 1000),\n",
    "            w_star.reshape(1000, 1000),\n",
    "            cmap=plt.get_cmap(\"RdYlBu\"),\n",
    "        )\n",
    "        ax[2, 1].contourf(\n",
    "            grid_x.reshape(1000, 1000),\n",
    "            grid_y.reshape(1000, 1000),\n",
    "            w_pred.reshape(1000, 1000),\n",
    "            cmap=plt.get_cmap(\"RdYlBu\"),\n",
    "        )\n",
    "        ax[0, 0].set_title(\"u_exact\")\n",
    "        ax[0, 1].set_title(\"u_pred\")\n",
    "        ax[1, 0].set_title(\"v_exact\")\n",
    "        ax[1, 1].set_title(\"v_pred\")\n",
    "        ax[2, 0].set_title(\"w_exact\")\n",
    "        ax[2, 1].set_title(\"w_pred\")\n",
    "        fig.savefig(OUTPUT_DIR + f\"/velocity_t={i}.png\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
